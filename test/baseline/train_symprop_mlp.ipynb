{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# here put the import lib\r\n",
    "import os\r\n",
    "import sys\r\n",
    "from collections import defaultdict\r\n",
    "import random\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import dataloader\r\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\r\n",
    "\r\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(\"\"))))\r\n",
    "from utils.data_utils import data_utils, data_process\r\n",
    "from utils.fetch_features import *\r\n",
    "from utils.torch_utils import torch_utils\r\n",
    "from models.baseline_mlp import baseline_lstm\r\n",
    "\r\n",
    "random.seed(35)\r\n",
    "plt.style.use(\"seaborn\")\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "print(\"torch.version:  \", torch.__version__)\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "print(\"current_device: \", device)\r\n",
    "\r\n",
    "if torch.cuda.is_available():\r\n",
    "    print(\"device_name:    \", torch.cuda.get_device_name(device))\r\n",
    "    # print(\"device_count:   \", torch.cuda.device_count())\r\n",
    "    # print(\"current_device: \", torch.cuda.current_device())\r\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:11:57.144876Z",
     "iopub.status.busy": "2021-08-24T02:11:57.144549Z",
     "iopub.status.idle": "2021-08-24T02:11:58.238763Z",
     "shell.execute_reply": "2021-08-24T02:11:58.238300Z",
     "shell.execute_reply.started": "2021-08-24T02:11:57.144808Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read action_state"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def trans_2_symbols(action_condition):\r\n",
    "    def generate_symbol_index(action_state_var):\r\n",
    "        sym = []\r\n",
    "        for symbol_variable in action_state_var.values():\r\n",
    "            for symbol in symbol_variable:\r\n",
    "                sym.append(symbol)\r\n",
    "\r\n",
    "        return \"symbol{}\".format(len(set(sym)))\r\n",
    "\r\n",
    "    action_state_var = defaultdict(list)\r\n",
    "    for action in [\"move\", \"pick_cube\", \"transport\", \"place_cube\"]:\r\n",
    "        symbol_varibales = {}\r\n",
    "        for symbol_data in action_condition[action]:\r\n",
    "            new_index = generate_symbol_index(action_state_var)\r\n",
    "            symbol_varibales[new_index] = symbol_data\r\n",
    "            action_state_var[action] = symbol_varibales\r\n",
    "\r\n",
    "    return action_state_var\r\n",
    "\r\n",
    "\r\n",
    "with open(\"eff_pos.json\", \"r\") as f:\r\n",
    "    content = json.load(f)\r\n",
    "\r\n",
    "action_state = trans_2_symbols(content)\r\n",
    "\r\n",
    "# with open(\"action_state_variable.json\", \"w\") as f:\r\n",
    "#     json.dump(action_state, f)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:12:02.397705Z",
     "iopub.status.busy": "2021-08-24T02:12:02.397433Z",
     "iopub.status.idle": "2021-08-24T02:12:02.433017Z",
     "shell.execute_reply": "2021-08-24T02:12:02.432424Z",
     "shell.execute_reply.started": "2021-08-24T02:12:02.397682Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# -----------------------------\r\n",
    "# read segmented trajectory data\r\n",
    "# -----------------------------\r\n",
    "\r\n",
    "\r\n",
    "def read_train_data(*file_names):\r\n",
    "    traj_list = []\r\n",
    "    for file_name in file_names:\r\n",
    "        temp = data_utils.read_from_pickle(\r\n",
    "            os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"archive\", \"processed\", file_name)\r\n",
    "        )\r\n",
    "        traj_list.extend(temp)\r\n",
    "    return traj_list\r\n",
    "\r\n",
    "\r\n",
    "traj_list = read_train_data(\"traj_stationary_65d.pickle\")\r\n",
    "\r\n",
    "\r\n",
    "def compute_mean_std(traj_list):\r\n",
    "    data_dict = {}\r\n",
    "    for action in FETCH_CAPABILITY_BASE:\r\n",
    "        data_dict.setdefault(action, [])\r\n",
    "\r\n",
    "    for traj in traj_list:\r\n",
    "        for action in traj:\r\n",
    "            data_dict[action].append(traj[action])\r\n",
    "\r\n",
    "    z_score_mean, z_score_std = data_process.compute_minibatch_mean_and_std(data_dict)\r\n",
    "    return z_score_mean, z_score_std\r\n",
    "\r\n",
    "\r\n",
    "# compute mean std\r\n",
    "z_score_mean, z_score_std = compute_mean_std(traj_list)\r\n",
    "np.save(\"baseline_lstm_mean.npy\", z_score_mean)\r\n",
    "np.save(\"baseline_lstm_std.npy\", z_score_std)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:12:16.948181Z",
     "iopub.status.busy": "2021-08-24T02:12:16.947911Z",
     "iopub.status.idle": "2021-08-24T02:12:36.503727Z",
     "shell.execute_reply": "2021-08-24T02:12:36.503211Z",
     "shell.execute_reply.started": "2021-08-24T02:12:16.948157Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate train_loader, test_loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z_score_mean = np.load(\"baseline_lstm_mean.npy\")\r\n",
    "z_score_std = np.load(\"baseline_lstm_std.npy\")\r\n",
    "\r\n",
    "\r\n",
    "def z_score_normalization(x, mean, std):\r\n",
    "    return (x - mean) / (std + 1e-5)\r\n",
    "\r\n",
    "\r\n",
    "class Collate_RNN:\r\n",
    "    def __init__(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "    def _collate(self, batch):\r\n",
    "\r\n",
    "        xs = [torch.FloatTensor(v[0]).to(device) for v in batch]\r\n",
    "        ys = torch.LongTensor([v[1] for v in batch])\r\n",
    "        # 获得每个样本的序列长度\r\n",
    "        seq_lengths = torch.LongTensor([v for v in map(len, xs)])\r\n",
    "        max_len = max([len(v) for v in xs])\r\n",
    "        # 每个样本都padding到当前batch的最大长度\r\n",
    "        xs = pad_sequence(xs, batch_first=True, padding_value=0)\r\n",
    "        # 把xs和ys按照序列长度从大到小排序\r\n",
    "        seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\r\n",
    "        xs = xs[perm_idx]\r\n",
    "        ys = ys[perm_idx]\r\n",
    "        return xs, seq_lengths, ys\r\n",
    "\r\n",
    "    def __call__(self, batch):\r\n",
    "        return self._collate(batch)\r\n",
    "\r\n",
    "\r\n",
    "def generate_training_dataset(action, symbol_states, traj_list, z_score_mean, z_score_std, time_step):\r\n",
    "    \"\"\"\r\n",
    "    @description  :  generate training dataset for action\r\n",
    "    ---------\r\n",
    "    @param  :\r\n",
    "    ---------\r\n",
    "    @Returns  :  X y\r\n",
    "    ---------\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    train_data = []\r\n",
    "    train_label = []\r\n",
    "    for _1_traj_data in traj_list:\r\n",
    "        for index in range(350, len(_1_traj_data[action][:-350]), 12):\r\n",
    "            if (index + time_step) < (len(_1_traj_data[action]) - 350):\r\n",
    "                train_data.append(np.array(_1_traj_data[action][index : index + time_step]))\r\n",
    "                train_label.append(0)\r\n",
    "        for index in range(len(_1_traj_data[action]) - 350, len(_1_traj_data[action]), 1):\r\n",
    "            if (index + time_step) < len(_1_traj_data[action]):\r\n",
    "                train_data.append(np.array(_1_traj_data[action][index : index + time_step]))\r\n",
    "                train_label.append(1)\r\n",
    "\r\n",
    "    label_0 = 0\r\n",
    "    label_1 = 0\r\n",
    "    for label in train_label:\r\n",
    "        if label == 0:\r\n",
    "            label_0 = label_0 + 1\r\n",
    "        elif label == 1:\r\n",
    "            label_1 = label_1 + 1\r\n",
    "    print(\"    Num of label 1: \", label_1)\r\n",
    "    print(\"    Num of label 0: \", label_0)\r\n",
    "\r\n",
    "    X = []\r\n",
    "    for x in train_data:\r\n",
    "        X.append(\r\n",
    "            data_process.select_features(\r\n",
    "                data_process.z_score_normalization(np.array(x).astype(float), z_score_mean, z_score_std), symbol_states\r\n",
    "            )  # .flatten()\r\n",
    "        )\r\n",
    "    X = np.array(X)\r\n",
    "    y = np.array(train_label)\r\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:12:50.805900Z",
     "iopub.status.busy": "2021-08-24T02:12:50.805632Z",
     "iopub.status.idle": "2021-08-24T02:12:50.819048Z",
     "shell.execute_reply": "2021-08-24T02:12:50.818676Z",
     "shell.execute_reply.started": "2021-08-24T02:12:50.805877Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_net(model, train_loader, test_loader):\r\n",
    "\r\n",
    "    train_losses = []\r\n",
    "    test_losses = []\r\n",
    "    avg_train_losses = []\r\n",
    "    avg_test_losses = []\r\n",
    "    test_accuracy = []\r\n",
    "    avg_test_accuracy = []\r\n",
    "\r\n",
    "    LR = 0.0003\r\n",
    "    EPOCH = 100\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=0.1)\r\n",
    "    loss_func = nn.CrossEntropyLoss()\r\n",
    "    _lambda = lambda epoch: 0.999 ** epoch\r\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=_lambda)\r\n",
    "\r\n",
    "    for epoch in range(EPOCH):\r\n",
    "\r\n",
    "        for step, (train_x, lengths, train_y) in enumerate(train_loader):\r\n",
    "\r\n",
    "            train_x = train_x.to(device)\r\n",
    "            train_y = train_y.to(device)\r\n",
    "            # train_y = train_y.unsqueeze(1)\r\n",
    "\r\n",
    "            # print('train_y: ', train_y.size(), train_y)\r\n",
    "            model.train()\r\n",
    "            train_x = pack_padded_sequence(train_x, lengths, batch_first=True)\r\n",
    "            output = model(train_x)\r\n",
    "\r\n",
    "            # print('output: ', output.size(), output)\r\n",
    "            # print(output.size())\r\n",
    "            loss = loss_func(output, train_y)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            scheduler.step()\r\n",
    "\r\n",
    "            if step % 50 == 0:\r\n",
    "\r\n",
    "                if torch.cuda.is_available():\r\n",
    "                    train_losses.append(loss.data.cpu().numpy())\r\n",
    "                else:\r\n",
    "                    train_losses.append(loss.data.numpy())\r\n",
    "\r\n",
    "                i = 0\r\n",
    "                total_size = 0\r\n",
    "\r\n",
    "                with torch.no_grad():\r\n",
    "                    for _, (test_x, lengths, test_y) in enumerate(test_loader):\r\n",
    "                        test_x = test_x.to(device)\r\n",
    "                        test_y = test_y.to(device)\r\n",
    "                        # test_y = test_y.unsqueeze(1)\r\n",
    "                        model.eval()\r\n",
    "                        test_x = pack_padded_sequence(test_x, lengths, batch_first=True)\r\n",
    "                        test_output = model(test_x)\r\n",
    "                        loss = loss_func(test_output, test_y)\r\n",
    "                        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\r\n",
    "\r\n",
    "                        for res in test_y.cpu().numpy() == pred_y:\r\n",
    "                            if res:\r\n",
    "                                i = i + 1\r\n",
    "                        total_size = total_size + test_output.size()[0]\r\n",
    "\r\n",
    "                    accuracy = i / total_size\r\n",
    "                    test_accuracy.append(accuracy)\r\n",
    "\r\n",
    "                    if torch.cuda.is_available():\r\n",
    "                        test_losses.append(loss.data.cpu().numpy())\r\n",
    "                    else:\r\n",
    "                        test_losses.append(loss.data.numpy())\r\n",
    "\r\n",
    "        avg_train_loss = np.average(train_losses)\r\n",
    "        avg_test_loss = np.average(test_losses)\r\n",
    "        avg_train_losses.append(avg_train_loss)\r\n",
    "        avg_test_losses.append(avg_test_loss)\r\n",
    "        avg_accuracy = np.average(test_accuracy)\r\n",
    "        avg_test_accuracy.append(avg_accuracy)\r\n",
    "\r\n",
    "        if (epoch + 1) % 10 == 0:\r\n",
    "            print_msg = \"Epoch: {}/{} | train loss: {:.4f} | test loss: {:.4f} | test accuracy: {:.4f}\".format(\r\n",
    "                epoch + 1,\r\n",
    "                EPOCH,\r\n",
    "                avg_train_loss,\r\n",
    "                avg_test_loss,\r\n",
    "                avg_accuracy,\r\n",
    "            )\r\n",
    "\r\n",
    "            print(print_msg)\r\n",
    "\r\n",
    "        # if torch_utils.early_stop(model=model, test_accuracy=avg_test_accuracy):\r\n",
    "        #     print(\"Early Stopping\")\r\n",
    "        #     break\r\n",
    "\r\n",
    "        train_losses = []\r\n",
    "        test_losses = []\r\n",
    "        test_accuracy = []\r\n",
    "\r\n",
    "    # model.load_state_dict(torch.load(\"checkpoint.pt\"))\r\n",
    "    return model, avg_train_losses, avg_test_losses"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:12:54.019925Z",
     "iopub.status.busy": "2021-08-24T02:12:54.019655Z",
     "iopub.status.idle": "2021-08-24T02:12:54.035935Z",
     "shell.execute_reply": "2021-08-24T02:12:54.035509Z",
     "shell.execute_reply.started": "2021-08-24T02:12:54.019902Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# start trainning\r\n",
    "\r\n",
    "BATCH_SIZE = 256\r\n",
    "TIME_STEP = 200\r\n",
    "\r\n",
    "for action in action_state:\r\n",
    "    print(action)\r\n",
    "    for symbol in action_state[action]:\r\n",
    "        print(\" \", symbol)\r\n",
    "\r\n",
    "        # 初始化symbol dataset\r\n",
    "        X, y = generate_training_dataset(\r\n",
    "            action, action_state[action][symbol], traj_list, z_score_mean, z_score_std, time_step=TIME_STEP\r\n",
    "        )\r\n",
    "\r\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\r\n",
    "        train_loader = dataloader.DataLoader(\r\n",
    "            dataset=list(zip(x_train, y_train)), batch_size=BATCH_SIZE, num_workers=0, shuffle=True, collate_fn=Collate_RNN()\r\n",
    "        )\r\n",
    "        test_loader = dataloader.DataLoader(\r\n",
    "            dataset=list(zip(x_test, y_test)), batch_size=BATCH_SIZE, num_workers=0, shuffle=True, collate_fn=Collate_RNN()\r\n",
    "        )\r\n",
    "\r\n",
    "        n_features = len(action_state[action][symbol])\r\n",
    "        model = baseline_lstm(n_features)\r\n",
    "        model.to(device)\r\n",
    "        # print(model)\r\n",
    "\r\n",
    "        print(\"    Start Train ...\")\r\n",
    "        model, avg_train_losses, avg_test_losses = train_net(model, train_loader, test_loader)\r\n",
    "        torch.save(model.state_dict(), \"models/{}.pt\".format(symbol))\r\n",
    "        print(\"    Training Finish\")\r\n",
    "        print()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T02:13:03.224813Z",
     "iopub.status.busy": "2021-08-24T02:13:03.224554Z",
     "iopub.status.idle": "2021-08-24T02:13:53.072329Z",
     "shell.execute_reply": "2021-08-24T02:13:53.071826Z",
     "shell.execute_reply.started": "2021-08-24T02:13:03.224790Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python389jvsc74a57bd0df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}